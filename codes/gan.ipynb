{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.utils as vutils\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "from torchvision.transforms import RandomRotation, RandomHorizontalFlip, RandomVerticalFlip, RandomResizedCrop\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define Generator\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self,nz,ngf,nc):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, nc, ndf):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False)  # This may output [B, 1, 11, 11] for 224x224 inputs\n",
    "        )\n",
    "        \n",
    "        # Adaptive pooling to force the spatial dimensions to 1x1\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.main(input)\n",
    "        # x will be [B, 1, H, W] (e.g., [16, 1, 11, 11] for 224x224 images)\n",
    "        x = self.pool(x)  # Now x is [B, 1, 1, 1]\n",
    "        x = x.view(x.size(0), -1)  # Flatten to [B, 1]\n",
    "        return self.sigmoid(x)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, images_root, image_files, transform=None, augmentations=None):\n",
    "        self.image_files = image_files\n",
    "        self.images_root = images_root\n",
    "        self.transform = transform\n",
    "        self.augmentations = augmentations\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = Image.open(os.path.join(self.images_root, img_path)).convert('RGB')\n",
    "\n",
    "        if self.augmentations:\n",
    "            image = self.augmentations(image)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "\n",
    "        return image\n",
    "\n",
    "    \n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, images_root, image_files, transform=None, augmentations=None):\n",
    "        self.image_files = image_files\n",
    "        self.images_root = images_root\n",
    "        self.transform = transform\n",
    "        self.augmentations = augmentations\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = Image.open(os.path.join(self.images_root, img_path)).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Determine the label based on the filename or directory structure\n",
    "        if 'worm' in self.image_files[idx].lower():  # assuming 'worm' indicates worm-cropped images\n",
    "            label = 1  # worm present\n",
    "        else:\n",
    "            label = 0  # no worm\n",
    "        \n",
    "        \n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example vae_loss function (you can replace this with your own)\n",
    "def vae_loss(reconstructed, original, mu, logvar):\n",
    "    \"\"\"\n",
    "    Compute the VAE loss.\n",
    "      - Reconstruction loss: binary cross-entropy between reconstructed and original image.\n",
    "      - KL divergence loss: forcing the latent space distribution closer to N(0,1)\n",
    "    Returns a tuple of (total_loss, recon_loss, kl_loss)\n",
    "    \"\"\"\n",
    "    bce = nn.functional.binary_cross_entropy(reconstructed, original, reduction='mean')\n",
    "    kl = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    total_loss = bce + kl\n",
    "    return total_loss, bce, kl\n",
    "\n",
    "def vae_loss_inference(reconstructed, original, mu, logvar):\n",
    "    recon_loss = nn.functional.mse_loss(reconstructed, original, reduction=\"none\")\n",
    "    kl_div = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return recon_loss + kl_div\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available splits: ['train', 'eval', 'test']\n",
      "Dataset sizes: {'train': 122, 'eval': 16, 'test': 35}\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "nz = 100  # Latent vector size\n",
    "ngf = 224  # Generator feature map size\n",
    "ndf = 224  # Discriminator feature map size\n",
    "nc = 3    # Number of channels (1 for grayscale, 3 for RGB)\n",
    "batch_size = 16\n",
    "epochs = 150\n",
    "lr = 0.0002\n",
    "beta1 = 0.5  # Adam optimizer beta1\n",
    "early_stop_patient = 150\n",
    "\n",
    "\n",
    "# Data loading\n",
    "data_root = \"./k-fold/fold_1\"\n",
    "splits = [\"train\", \"eval\", \"test\"]\n",
    "\n",
    "data_dict = {}\n",
    "datasets_dict = {}\n",
    "\n",
    "\n",
    "data_transforms = transforms.Compose([\n",
    "    RandomRotation(degrees=30),  # Randomly rotate images by up to 30 degrees\n",
    "    RandomHorizontalFlip(p=0.5),  # Randomly flip images horizontally with a probability of 0.5\n",
    "    RandomVerticalFlip(p=0.5),  # Randomly flip images vertically with a probability of 0.5\n",
    "    RandomResizedCrop(size=(224, 224), scale=(0.8, 1.0))  # Randomly crop and resize images to 128x128 with a scale between 80% and 100% of the original size\n",
    "])\n",
    "\n",
    "\n",
    "# Load CSV files and create datasets\n",
    "for split in splits:\n",
    "    try:\n",
    "        # Load CSV data\n",
    "        csv_path =  f\"{data_root}/{split}/{split}.csv\"\n",
    "        data_dict[split] = pd.read_csv(csv_path)\n",
    "        # print(data_dict[\"train\"]['filename'].values)\n",
    "        # Create dataset for each split\n",
    "        datasets_dict[split] = TestDataset(\n",
    "            images_root=\"./data/\",\n",
    "            image_files=data_dict[split]['filename'].values,\n",
    "            transform=transforms.Compose([\n",
    "                transforms.Resize((224, 224)),\n",
    "                transforms.ToTensor()\n",
    "            ]),\n",
    "            augmentations=data_transforms if split == \"train\" else None\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {split} split: {e}\")\n",
    "\n",
    "# Create dataloaders\n",
    "dataloaders = {\n",
    "    split: DataLoader(\n",
    "        datasets_dict[split],\n",
    "        batch_size=batch_size if split == \"train\" else 1,\n",
    "        shuffle=(split == \"train\"),\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    ) for split in splits\n",
    "}\n",
    "\n",
    "print(\"Available splits:\", list(datasets_dict.keys()))\n",
    "print(\"Dataset sizes:\", {split: len(dataset) for split, dataset in datasets_dict.items()})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/150] Loss D: 0.7335, Loss G: 2.1064\n",
      "Epoch [2/150] Loss D: 0.3748, Loss G: 3.0677\n",
      "Epoch [3/150] Loss D: 0.2093, Loss G: 3.4999\n",
      "Epoch [4/150] Loss D: 0.1251, Loss G: 3.8794\n",
      "Epoch [5/150] Loss D: 0.0823, Loss G: 4.1670\n",
      "Epoch [6/150] Loss D: 0.0575, Loss G: 4.4120\n",
      "Epoch [7/150] Loss D: 0.0411, Loss G: 4.7333\n",
      "Epoch [8/150] Loss D: 0.0322, Loss G: 4.8823\n",
      "Epoch [9/150] Loss D: 0.0255, Loss G: 5.0728\n",
      "Epoch [10/150] Loss D: 0.0211, Loss G: 5.2391\n",
      "Epoch [11/150] Loss D: 0.0168, Loss G: 5.4758\n",
      "Epoch [12/150] Loss D: 0.0149, Loss G: 5.5459\n",
      "Epoch [13/150] Loss D: 0.0125, Loss G: 5.7336\n",
      "Epoch [14/150] Loss D: 0.0107, Loss G: 5.9032\n",
      "Epoch [15/150] Loss D: 0.0095, Loss G: 6.0279\n",
      "Epoch [16/150] Loss D: 0.0081, Loss G: 6.1361\n",
      "Epoch [17/150] Loss D: 0.0072, Loss G: 6.2284\n",
      "Epoch [18/150] Loss D: 0.0068, Loss G: 6.1869\n",
      "Epoch [19/150] Loss D: 0.0059, Loss G: 6.3526\n",
      "Epoch [20/150] Loss D: 0.0055, Loss G: 6.4088\n",
      "Epoch [21/150] Loss D: 0.0049, Loss G: 6.5244\n",
      "Epoch [22/150] Loss D: 0.0044, Loss G: 6.6472\n",
      "Epoch [23/150] Loss D: 0.0040, Loss G: 6.7436\n",
      "Epoch [24/150] Loss D: 0.0036, Loss G: 6.8018\n",
      "Epoch [25/150] Loss D: 0.0035, Loss G: 6.8189\n",
      "Epoch [26/150] Loss D: 0.0032, Loss G: 6.9354\n",
      "Epoch [27/150] Loss D: 0.0029, Loss G: 7.0364\n",
      "Epoch [28/150] Loss D: 0.0026, Loss G: 7.1148\n",
      "Epoch [29/150] Loss D: 0.0026, Loss G: 7.1221\n",
      "Epoch [30/150] Loss D: 0.0025, Loss G: 7.1174\n",
      "Epoch [31/150] Loss D: 0.0023, Loss G: 7.2033\n",
      "Epoch [32/150] Loss D: 0.0022, Loss G: 7.2770\n",
      "Epoch [33/150] Loss D: 0.0020, Loss G: 7.3524\n",
      "Epoch [34/150] Loss D: 0.0019, Loss G: 7.3984\n",
      "Epoch [35/150] Loss D: 0.0018, Loss G: 7.5235\n",
      "Epoch [36/150] Loss D: 0.0016, Loss G: 7.6398\n",
      "Epoch [37/150] Loss D: 0.0016, Loss G: 7.6263\n",
      "Epoch [38/150] Loss D: 0.0015, Loss G: 7.6711\n",
      "Epoch [39/150] Loss D: 0.0015, Loss G: 7.6858\n",
      "Epoch [40/150] Loss D: 0.0015, Loss G: 7.7156\n",
      "Epoch [41/150] Loss D: 0.0014, Loss G: 7.8708\n",
      "Epoch [42/150] Loss D: 0.0014, Loss G: 8.0495\n",
      "Epoch [43/150] Loss D: 0.0012, Loss G: 8.2180\n",
      "Epoch [44/150] Loss D: 0.0011, Loss G: 8.2580\n",
      "Epoch [45/150] Loss D: 0.0010, Loss G: 8.2076\n",
      "Epoch [46/150] Loss D: 0.0009, Loss G: 8.3411\n",
      "Epoch [47/150] Loss D: 0.0009, Loss G: 8.4217\n",
      "Epoch [48/150] Loss D: 0.0008, Loss G: 8.4548\n",
      "Epoch [49/150] Loss D: 0.0008, Loss G: 8.4259\n",
      "Epoch [50/150] Loss D: 0.0008, Loss G: 8.2377\n",
      "Epoch [51/150] Loss D: 0.0008, Loss G: 8.2675\n",
      "Epoch [52/150] Loss D: 0.0008, Loss G: 8.2807\n",
      "Epoch [53/150] Loss D: 0.0007, Loss G: 8.2844\n",
      "Epoch [54/150] Loss D: 0.0007, Loss G: 8.3171\n",
      "Epoch [55/150] Loss D: 0.0007, Loss G: 8.3423\n",
      "Epoch [56/150] Loss D: 0.0007, Loss G: 8.3332\n",
      "Epoch [57/150] Loss D: 0.0007, Loss G: 8.2062\n",
      "Epoch [58/150] Loss D: 0.0007, Loss G: 8.1851\n",
      "Epoch [59/150] Loss D: 0.0006, Loss G: 8.2914\n",
      "Epoch [60/150] Loss D: 0.0006, Loss G: 8.3134\n",
      "Epoch [61/150] Loss D: 0.0006, Loss G: 8.3120\n",
      "Epoch [62/150] Loss D: 0.0006, Loss G: 8.2878\n",
      "Epoch [63/150] Loss D: 0.0006, Loss G: 8.1844\n",
      "Epoch [64/150] Loss D: 0.0006, Loss G: 8.2255\n",
      "Epoch [65/150] Loss D: 0.0006, Loss G: 8.2902\n",
      "Epoch [66/150] Loss D: 0.0006, Loss G: 8.3133\n",
      "Epoch [67/150] Loss D: 0.0006, Loss G: 8.3531\n",
      "Epoch [68/150] Loss D: 0.0005, Loss G: 8.3957\n",
      "Epoch [69/150] Loss D: 0.0005, Loss G: 8.4445\n",
      "Epoch [70/150] Loss D: 0.0005, Loss G: 8.5046\n",
      "Epoch [71/150] Loss D: 0.0005, Loss G: 8.5604\n",
      "Epoch [72/150] Loss D: 0.0005, Loss G: 8.6097\n",
      "Epoch [73/150] Loss D: 0.0005, Loss G: 8.6667\n",
      "Epoch [74/150] Loss D: 0.0004, Loss G: 8.7232\n",
      "Epoch [75/150] Loss D: 0.0004, Loss G: 8.7692\n",
      "Epoch [76/150] Loss D: 0.0004, Loss G: 8.7993\n",
      "Epoch [77/150] Loss D: 0.0004, Loss G: 8.8264\n",
      "Epoch [78/150] Loss D: 0.0004, Loss G: 8.8581\n",
      "Epoch [79/150] Loss D: 0.0004, Loss G: 8.8858\n",
      "Epoch [80/150] Loss D: 0.0004, Loss G: 8.9156\n",
      "Epoch [81/150] Loss D: 0.0004, Loss G: 8.9374\n",
      "Epoch [82/150] Loss D: 0.0003, Loss G: 8.9741\n",
      "Epoch [83/150] Loss D: 0.0003, Loss G: 9.0177\n",
      "Epoch [84/150] Loss D: 0.0003, Loss G: 9.0544\n",
      "Epoch [85/150] Loss D: 0.0003, Loss G: 9.0809\n",
      "Epoch [86/150] Loss D: 0.0003, Loss G: 9.0911\n",
      "Epoch [87/150] Loss D: 0.0003, Loss G: 9.0935\n",
      "Epoch [88/150] Loss D: 0.0003, Loss G: 9.0943\n",
      "Epoch [89/150] Loss D: 0.0003, Loss G: 9.1030\n",
      "Epoch [90/150] Loss D: 0.0003, Loss G: 9.1391\n",
      "Epoch [91/150] Loss D: 0.0003, Loss G: 9.1733\n",
      "Epoch [92/150] Loss D: 0.0003, Loss G: 9.2107\n",
      "Epoch [93/150] Loss D: 0.0003, Loss G: 9.2290\n",
      "Epoch [94/150] Loss D: 0.0003, Loss G: 9.2610\n",
      "Epoch [95/150] Loss D: 0.0003, Loss G: 9.2902\n",
      "Epoch [96/150] Loss D: 0.0002, Loss G: 9.3192\n",
      "Epoch [97/150] Loss D: 0.0002, Loss G: 9.3399\n",
      "Epoch [98/150] Loss D: 0.0002, Loss G: 9.3807\n",
      "Epoch [99/150] Loss D: 0.0002, Loss G: 9.4128\n",
      "Epoch [100/150] Loss D: 0.0002, Loss G: 9.4602\n",
      "Epoch [101/150] Loss D: 0.0002, Loss G: 9.4945\n",
      "Epoch [102/150] Loss D: 0.0002, Loss G: 9.5146\n",
      "Epoch [103/150] Loss D: 0.0002, Loss G: 9.5422\n",
      "Epoch [104/150] Loss D: 0.0002, Loss G: 9.5603\n",
      "Epoch [105/150] Loss D: 0.0002, Loss G: 9.5750\n",
      "Epoch [106/150] Loss D: 0.0002, Loss G: 9.5819\n",
      "Epoch [107/150] Loss D: 0.0002, Loss G: 9.5878\n",
      "Epoch [108/150] Loss D: 0.0002, Loss G: 9.6140\n",
      "Epoch [109/150] Loss D: 0.0002, Loss G: 9.6377\n",
      "Epoch [110/150] Loss D: 0.0002, Loss G: 9.6582\n",
      "Epoch [111/150] Loss D: 0.0002, Loss G: 9.6691\n",
      "Epoch [112/150] Loss D: 0.0002, Loss G: 9.6856\n",
      "Epoch [113/150] Loss D: 0.0002, Loss G: 9.7041\n",
      "Epoch [114/150] Loss D: 0.0002, Loss G: 9.7300\n",
      "Epoch [115/150] Loss D: 0.0002, Loss G: 9.7625\n",
      "Epoch [116/150] Loss D: 0.0002, Loss G: 9.7856\n",
      "Epoch [117/150] Loss D: 0.0002, Loss G: 9.8093\n",
      "Epoch [118/150] Loss D: 0.0002, Loss G: 9.8309\n",
      "Epoch [119/150] Loss D: 0.0002, Loss G: 9.8509\n",
      "Epoch [120/150] Loss D: 0.0002, Loss G: 9.8691\n",
      "Epoch [121/150] Loss D: 0.0002, Loss G: 9.8862\n",
      "Epoch [122/150] Loss D: 0.0001, Loss G: 9.9108\n",
      "Epoch [123/150] Loss D: 0.0001, Loss G: 9.9421\n",
      "Epoch [124/150] Loss D: 0.0001, Loss G: 9.9514\n",
      "Epoch [125/150] Loss D: 0.0001, Loss G: 9.9749\n",
      "Epoch [126/150] Loss D: 0.0001, Loss G: 9.9913\n",
      "Epoch [127/150] Loss D: 0.0001, Loss G: 10.0129\n",
      "Epoch [128/150] Loss D: 0.0001, Loss G: 10.0331\n",
      "Epoch [129/150] Loss D: 0.0001, Loss G: 10.0537\n",
      "Epoch [130/150] Loss D: 0.0001, Loss G: 10.0724\n",
      "Epoch [131/150] Loss D: 0.0001, Loss G: 10.0934\n",
      "Epoch [132/150] Loss D: 0.0001, Loss G: 10.1059\n",
      "Epoch [133/150] Loss D: 0.0001, Loss G: 10.1189\n",
      "Epoch [134/150] Loss D: 0.0001, Loss G: 10.1362\n",
      "Epoch [135/150] Loss D: 0.0001, Loss G: 10.1572\n",
      "Epoch [136/150] Loss D: 0.0001, Loss G: 10.1730\n",
      "Epoch [137/150] Loss D: 0.0001, Loss G: 10.1884\n",
      "Epoch [138/150] Loss D: 0.0001, Loss G: 10.1955\n",
      "Epoch [139/150] Loss D: 0.0001, Loss G: 10.2033\n",
      "Epoch [140/150] Loss D: 0.0001, Loss G: 10.2161\n",
      "Epoch [141/150] Loss D: 0.0001, Loss G: 10.2308\n",
      "Epoch [142/150] Loss D: 0.0001, Loss G: 10.2329\n",
      "Epoch [143/150] Loss D: 0.0001, Loss G: 10.2428\n",
      "Epoch [144/150] Loss D: 0.0001, Loss G: 10.2509\n",
      "Epoch [145/150] Loss D: 0.0001, Loss G: 10.2679\n",
      "Epoch [146/150] Loss D: 0.0001, Loss G: 10.2802\n",
      "Epoch [147/150] Loss D: 0.0001, Loss G: 10.2967\n",
      "Epoch [148/150] Loss D: 0.0001, Loss G: 10.3144\n",
      "Epoch [149/150] Loss D: 0.0001, Loss G: 10.3352\n",
      "Epoch [150/150] Loss D: 0.0001, Loss G: 10.3441\n",
      "Training Complete!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize models\n",
    "generator = Generator(nz,ngf,nc).to(device)\n",
    "discriminator = Discriminator(nc, ndf).to(device)\n",
    "\n",
    "generator.apply(lambda m: nn.init.normal_(m.weight, 0, 0.02) if hasattr(m, 'weight') else None)\n",
    "discriminator.apply(lambda m: nn.init.normal_(m.weight, 0, 0.02) if hasattr(m, 'weight') else None)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizerG = optim.Adam(generator.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerD = optim.Adam(discriminator.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(epochs):\n",
    "    for real_images,_ in dataloaders[\"train\"]:\n",
    "        real_images = real_images.to(device)\n",
    "        batch_size = real_images.size(0)\n",
    "        # print(real_images.shape)\n",
    "        # Train Discriminator\n",
    "        noise = torch.randn(batch_size, nz, 1, 1, device=device)\n",
    "        fake_images = generator(noise)\n",
    "        \n",
    "        real_labels = torch.ones(batch_size, 1, device=device)\n",
    "        fake_labels = torch.zeros(batch_size, 1, device=device)\n",
    "        \n",
    "        optimizerD.zero_grad()\n",
    "        output_real = discriminator(real_images)\n",
    "        # print(output_real.shape)\n",
    "        # print(real_labels.shape)\n",
    "        output_fake = discriminator(fake_images.detach())\n",
    "        # print(output_fake.shape)\n",
    "        # print(fake_labels.shape)\n",
    "\n",
    "        lossD = criterion(output_real, real_labels) + criterion(output_fake, fake_labels)\n",
    "        lossD.backward()\n",
    "        optimizerD.step()\n",
    "        \n",
    "        # Train Generator\n",
    "        optimizerG.zero_grad()\n",
    "        output_fake = discriminator(fake_images)\n",
    "        lossG = criterion(output_fake, real_labels)\n",
    "        lossG.backward()\n",
    "        optimizerG.step()\n",
    "        \n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] Loss D: {lossD.item():.4f}, Loss G: {lossG.item():.4f}\")\n",
    "    \n",
    "    # Save sample images\n",
    "    if epoch % 10 == 0:\n",
    "        vutils.save_image(fake_images, f\"reconstruction_images/epoch_{epoch}.png\", normalize=True)\n",
    "        torch.save(generator.state_dict(), \"./models/gen.pth\")\n",
    "        torch.save(discriminator.state_dict(), \"./models/disc.pth\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"Training Complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_anomaly_threshold(gen, disc, test_data_loader, device):\n",
    "    gen.eval()\n",
    "    disc.eval()\n",
    "    anomaly_scores = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for real_images,_ in test_data_loader:  \n",
    "            real_images = real_images.to(device)\n",
    "            batch_size = real_images.size(0)\n",
    "\n",
    "            # Generate fake images\n",
    "            noise = torch.randn(batch_size, nz, 1, 1, device=device)  # Assuming `nz` is the latent space size\n",
    "            fake_images = gen(noise)\n",
    "\n",
    "            # Get discriminator predictions\n",
    "            real_preds = disc(real_images)  # Should be close to 1 for real images\n",
    "            fake_preds = disc(fake_images)  # Should be close to 0 for fake images\n",
    "            \n",
    "            # Compute anomaly score as the difference between real and fake scores\n",
    "            anomaly_score = torch.abs(real_preds - fake_preds)  # The more different, the more anomalous\n",
    "            anomaly_scores.extend(anomaly_score.cpu().numpy())  # Store anomaly scores\n",
    "\n",
    "    # Convert scores to tensor for statistical calculations\n",
    "    anomaly_scores = torch.tensor(anomaly_scores, device=device)\n",
    "\n",
    "    # Compute threshold (mean + std/2)\n",
    "    mean_score = anomaly_scores.mean().item()\n",
    "    std_score = anomaly_scores.std().item()\n",
    "    anomaly_threshold = mean_score + std_score\n",
    "\n",
    "\n",
    "    # Log information\n",
    "    print(f\"Mean Anomaly Score: {mean_score}, Std: {std_score}\")\n",
    "    print(f\"Anomaly Threshold: {anomaly_threshold}\")\n",
    "\n",
    "    return anomaly_threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_gan(gen, disc, test_data_loader, anomaly_threshold, device):\n",
    "    gen.eval()  \n",
    "    disc.eval()  \n",
    "\n",
    "    anomalies = []\n",
    "    true_labels = []  \n",
    "    pred_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for real_images, labels in test_data_loader:\n",
    "            real_images = real_images.to(device)\n",
    "            true_labels.extend(labels.cpu().numpy())  \n",
    "\n",
    "            batch_size = real_images.size(0)\n",
    "\n",
    "            # Generate fake images\n",
    "            noise = torch.randn(batch_size, nz, 1, 1, device=device)  # Assuming `nz` is latent size\n",
    "            fake_images = gen(noise)\n",
    "\n",
    "            # Discriminator scores\n",
    "            real_scores = disc(real_images).squeeze()  # Get scores for real images\n",
    "            fake_scores = disc(fake_images).squeeze()  # Get scores for generated images\n",
    "\n",
    "            # Compute anomaly score as absolute difference\n",
    "            anomaly_scores = torch.abs(real_scores - fake_scores)\n",
    "            print(anomaly_scores)\n",
    "\n",
    "            # Classify images based on anomaly threshold\n",
    "            if anomaly_scores >anomaly_threshold:\n",
    "                anomalies.append((\"no tericho\", anomaly_scores))  # Anomalous (not tericho)\n",
    "                pred_labels.append(0)\n",
    "            else:\n",
    "                anomalies.append((\"tericho\",anomaly_scores))  # Normal (tericho)\n",
    "                pred_labels.append(1)\n",
    "\n",
    "    return real_images, fake_images, anomalies, true_labels, pred_labels  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Anomaly Score: 0.9522849917411804, Std: 0.0013087138067930937\n",
      "Anomaly Threshold: 0.9535937055479735\n",
      "0.9535937055479735\n"
     ]
    }
   ],
   "source": [
    "th = detect_anomaly_threshold(gen= generator, disc = discriminator,test_data_loader=dataloaders['eval'],device=device)\n",
    "print(th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9527, device='cuda:0')\n",
      "tensor(0.9556, device='cuda:0')\n",
      "tensor(0.9549, device='cuda:0')\n",
      "tensor(0.9529, device='cuda:0')\n",
      "tensor(0.9564, device='cuda:0')\n",
      "tensor(0.9568, device='cuda:0')\n",
      "tensor(0.9565, device='cuda:0')\n",
      "tensor(0.9563, device='cuda:0')\n",
      "tensor(0.9554, device='cuda:0')\n",
      "tensor(0.9555, device='cuda:0')\n",
      "tensor(0.9529, device='cuda:0')\n",
      "tensor(0.9529, device='cuda:0')\n",
      "tensor(0.9534, device='cuda:0')\n",
      "tensor(0.9510, device='cuda:0')\n",
      "tensor(0.9539, device='cuda:0')\n",
      "tensor(0.9518, device='cuda:0')\n",
      "tensor(0.9539, device='cuda:0')\n",
      "tensor(0.9531, device='cuda:0')\n",
      "tensor(0.9524, device='cuda:0')\n",
      "tensor(0.9515, device='cuda:0')\n",
      "tensor(0.9521, device='cuda:0')\n",
      "tensor(0.9521, device='cuda:0')\n",
      "tensor(0.9528, device='cuda:0')\n",
      "tensor(0.9523, device='cuda:0')\n",
      "tensor(0.9544, device='cuda:0')\n",
      "tensor(0.9523, device='cuda:0')\n",
      "tensor(0.9519, device='cuda:0')\n",
      "tensor(0.9519, device='cuda:0')\n",
      "tensor(0.9532, device='cuda:0')\n",
      "tensor(0.9528, device='cuda:0')\n",
      "tensor(0.9536, device='cuda:0')\n",
      "tensor(0.9524, device='cuda:0')\n",
      "tensor(0.9526, device='cuda:0')\n",
      "tensor(0.9529, device='cuda:0')\n",
      "tensor(0.9523, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "images, reconstructed ,anomalies, true_labels, pred_labels = test_gan(gen= generator, disc = discriminator , test_data_loader=dataloaders['test'] , anomaly_threshold=th ,device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix , f1_score\n",
    "f1 = f1_score(true_labels, pred_labels)\n",
    "print(f1)\n",
    "# print(classification_report(true_labels, pred_labels))\n",
    "# print(confusion_matrix(true_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1)]\n"
     ]
    }
   ],
   "source": [
    "print(pred_labels)\n",
    "print(true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('wormed', tensor(0.9527, device='cuda:0')), ('no wormed', tensor(0.9556, device='cuda:0')), ('no wormed', tensor(0.9549, device='cuda:0')), ('wormed', tensor(0.9529, device='cuda:0')), ('no wormed', tensor(0.9564, device='cuda:0')), ('no wormed', tensor(0.9568, device='cuda:0')), ('no wormed', tensor(0.9565, device='cuda:0')), ('no wormed', tensor(0.9563, device='cuda:0'))]\n"
     ]
    }
   ],
   "source": [
    "print(anomalies[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('wormed', 158.14205932617188), ('wormed', 178.74172973632812), ('wormed', 207.54083251953125), ('wormed', 196.41542053222656), ('wormed', 223.1368408203125), ('no wormed', 247.09848022460938), ('wormed', 217.18492126464844), ('wormed', 192.02735900878906), ('wormed', 186.51715087890625), ('wormed', 219.11318969726562), ('wormed', 223.01605224609375), ('no wormed', 253.3943634033203), ('wormed', 230.77816772460938), ('wormed', 207.63681030273438), ('no wormed', 343.3358154296875), ('wormed', 187.82064819335938), ('no wormed', 387.0472106933594), ('no wormed', 355.0072021484375), ('no wormed', 351.0190124511719), ('no wormed', 369.83599853515625), ('wormed', 193.2080535888672), ('wormed', 210.8118438720703), ('no wormed', 282.4904479980469), ('wormed', 227.77255249023438), ('wormed', 198.7176055908203), ('wormed', 193.2436981201172), ('wormed', 219.24148559570312)]\n"
     ]
    }
   ],
   "source": [
    "print(anomalies[8:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available splits: ['test']\n",
      "Dataset sizes: {'test': 17}\n"
     ]
    }
   ],
   "source": [
    "# ==============\n",
    "# This cell is for testing some posetive and negative samples the repeated code here is for loading model \n",
    "# ==============\n",
    "\n",
    "\n",
    "# Hyperparameters\n",
    "nz = 100  # Latent vector size\n",
    "ngf = 224  # Generator feature map size\n",
    "ndf = 224  # Discriminator feature map size\n",
    "nc = 3    # Number of channels (1 for grayscale, 3 for RGB)\n",
    "batch_size = 16\n",
    "epochs = 150\n",
    "lr = 0.0002\n",
    "beta1 = 0.5  # Adam optimizer beta1\n",
    "early_stop_patient = 150\n",
    "\n",
    "\n",
    "# Data loading\n",
    "data_root = \"./test\"\n",
    "splits = [\"test\"]\n",
    "\n",
    "data_dict = {}\n",
    "datasets_dict = {}\n",
    "\n",
    "\n",
    "data_transforms = transforms.Compose([\n",
    "    RandomRotation(degrees=30),  # Randomly rotate images by up to 30 degrees\n",
    "    RandomHorizontalFlip(p=0.5),  # Randomly flip images horizontally with a probability of 0.5\n",
    "    RandomVerticalFlip(p=0.5),  # Randomly flip images vertically with a probability of 0.5\n",
    "    RandomResizedCrop(size=(224, 224), scale=(0.8, 1.0))  # Randomly crop and resize images to 128x128 with a scale between 80% and 100% of the original size\n",
    "])\n",
    "\n",
    "\n",
    "# Load CSV files and create datasets\n",
    "for split in splits:\n",
    "    try:\n",
    "        # Load CSV data\n",
    "        csv_path =  f\"{data_root}/test.csv\"\n",
    "        data_dict[split] = pd.read_csv(csv_path)\n",
    "        # print(data_dict[\"train\"]['filename'].values)\n",
    "        # Create dataset for each split\n",
    "        datasets_dict[split] = TestDataset(\n",
    "            images_root=\"./test/\",\n",
    "            image_files=data_dict[split]['filename'].values,\n",
    "            transform=transforms.Compose([\n",
    "                transforms.Resize((224, 224)),\n",
    "                transforms.ToTensor()\n",
    "            ]),\n",
    "            augmentations=data_transforms if split == \"train\" else None\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {split} split: {e}\")\n",
    "\n",
    "# Create dataloaders\n",
    "test_data_loader = DataLoader(\n",
    "    datasets_dict[\"test\"],\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(\"Available splits:\", list(datasets_dict.keys()))\n",
    "print(\"Dataset sizes:\", {split: len(dataset) for split, dataset in datasets_dict.items()})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9518, device='cuda:0')\n",
      "tensor(0.9549, device='cuda:0')\n",
      "tensor(0.9533, device='cuda:0')\n",
      "tensor(0.9528, device='cuda:0')\n",
      "tensor(0.9522, device='cuda:0')\n",
      "tensor(0.9532, device='cuda:0')\n",
      "tensor(0.9531, device='cuda:0')\n",
      "tensor(0.9533, device='cuda:0')\n",
      "tensor(0.9521, device='cuda:0')\n",
      "tensor(0.9563, device='cuda:0')\n",
      "tensor(0.9536, device='cuda:0')\n",
      "tensor(0.9535, device='cuda:0')\n",
      "tensor(0.9511, device='cuda:0')\n",
      "tensor(0.9504, device='cuda:0')\n",
      "tensor(0.9507, device='cuda:0')\n",
      "tensor(0.9520, device='cuda:0')\n",
      "tensor(0.9515, device='cuda:0')\n",
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "images, reconstructed ,anomalies, true_labels, pred_labels = test_gan(gen= generator, disc = discriminator , test_data_loader=test_data_loader, anomaly_threshold=th ,device=device)\n",
    "f1 = f1_score(true_labels, pred_labels)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1]\n",
      "[np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0)]\n"
     ]
    }
   ],
   "source": [
    "print(pred_labels)\n",
    "print(true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('wormed', tensor(0.9518, device='cuda:0')), ('no wormed', tensor(0.9549, device='cuda:0')), ('wormed', tensor(0.9533, device='cuda:0')), ('wormed', tensor(0.9528, device='cuda:0')), ('wormed', tensor(0.9522, device='cuda:0')), ('wormed', tensor(0.9532, device='cuda:0')), ('wormed', tensor(0.9531, device='cuda:0')), ('wormed', tensor(0.9533, device='cuda:0')), ('wormed', tensor(0.9521, device='cuda:0'))]\n"
     ]
    }
   ],
   "source": [
    "print(anomalies[:9])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('no wormed', tensor(0.9563, device='cuda:0')), ('wormed', tensor(0.9536, device='cuda:0')), ('wormed', tensor(0.9535, device='cuda:0')), ('wormed', tensor(0.9511, device='cuda:0')), ('wormed', tensor(0.9504, device='cuda:0')), ('wormed', tensor(0.9507, device='cuda:0')), ('wormed', tensor(0.9520, device='cuda:0')), ('wormed', tensor(0.9515, device='cuda:0'))]\n"
     ]
    }
   ],
   "source": [
    "print(anomalies[9:])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
